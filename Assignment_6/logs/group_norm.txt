
(eva-venv) C:\Users\Avinash\Documents\EVA6-PHASE1\Extensive-Vision-AI\Assignment_6>
(eva-venv) C:\Users\Avinash\Documents\EVA6-PHASE1\Extensive-Vision-AI\Assignment_6>
(eva-venv) C:\Users\Avinash\Documents\EVA6-PHASE1\Extensive-Vision-AI\Assignment_6>python main.py
=============== Running group_norm Model ===============
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 8, 26, 26]              72
              ReLU-2            [-1, 8, 26, 26]               0
         GroupNorm-3            [-1, 8, 26, 26]              16
           Dropout-4            [-1, 8, 26, 26]               0
            Conv2d-5           [-1, 16, 24, 24]           1,152
              ReLU-6           [-1, 16, 24, 24]               0
         GroupNorm-7           [-1, 16, 24, 24]              32
           Dropout-8           [-1, 16, 24, 24]               0
         MaxPool2d-9           [-1, 16, 12, 12]               0
           Conv2d-10            [-1, 8, 12, 12]             128
           Conv2d-11           [-1, 16, 10, 10]           1,152
             ReLU-12           [-1, 16, 10, 10]               0
        GroupNorm-13           [-1, 16, 10, 10]              32
          Dropout-14           [-1, 16, 10, 10]               0
           Conv2d-15             [-1, 16, 8, 8]           2,304
             ReLU-16             [-1, 16, 8, 8]               0
        GroupNorm-17             [-1, 16, 8, 8]              32
          Dropout-18             [-1, 16, 8, 8]               0
           Conv2d-19             [-1, 16, 6, 6]           2,304
             ReLU-20             [-1, 16, 6, 6]               0
        GroupNorm-21             [-1, 16, 6, 6]              32
          Dropout-22             [-1, 16, 6, 6]               0
        AvgPool2d-23             [-1, 16, 1, 1]               0
           Conv2d-24             [-1, 16, 1, 1]             256
             ReLU-25             [-1, 16, 1, 1]               0
        GroupNorm-26             [-1, 16, 1, 1]              32
          Dropout-27             [-1, 16, 1, 1]               0
           Conv2d-28             [-1, 10, 1, 1]             160
================================================================
Total params: 7,704
Trainable params: 7,704
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.57
Params size (MB): 0.03
Estimated Total Size (MB): 0.60
----------------------------------------------------------------
None
Epoch1 : Loss=0.3023398220539093  Accuracy=72.47 Batch_id=937: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:42<00:00, 22.30it/s]

Test set: Average loss: 0.1489, Accuracy: 9681/10000 (96.81%)

Epoch2 : Loss=0.28410792350769043  Accuracy=93.77 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:43<00:00, 21.52it/s]

Test set: Average loss: 0.0851, Accuracy: 9761/10000 (97.61%)

Epoch3 : Loss=0.05640270188450813  Accuracy=95.72 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:46<00:00, 20.34it/s]

Test set: Average loss: 0.0505, Accuracy: 9851/10000 (98.51%)

Epoch4 : Loss=0.15754354000091553  Accuracy=96.41 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.43it/s]

Test set: Average loss: 0.0358, Accuracy: 9897/10000 (98.97%)

Epoch5 : Loss=0.07215435802936554  Accuracy=96.85 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.45it/s]

Test set: Average loss: 0.0437, Accuracy: 9880/10000 (98.80%)

Epoch6 : Loss=0.07413476705551147  Accuracy=97.14 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:46<00:00, 20.34it/s]

Test set: Average loss: 0.0311, Accuracy: 9909/10000 (99.09%)

Epoch7 : Loss=0.06276421993970871  Accuracy=97.48 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.49it/s]

Test set: Average loss: 0.0342, Accuracy: 9897/10000 (98.97%)

Epoch8 : Loss=0.06492457538843155  Accuracy=97.70 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:50<00:00, 18.60it/s]

Test set: Average loss: 0.0337, Accuracy: 9904/10000 (99.04%)

Epoch9 : Loss=0.0867326483130455  Accuracy=97.73 Batch_id=937: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.54it/s]

Test set: Average loss: 0.0236, Accuracy: 9931/10000 (99.31%)

Epoch10 : Loss=0.3263237476348877  Accuracy=97.91 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.59it/s]

Test set: Average loss: 0.0260, Accuracy: 9914/10000 (99.14%)

Epoch11 : Loss=0.07458151131868362  Accuracy=98.06 Batch_id=937: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.61it/s]

Test set: Average loss: 0.0277, Accuracy: 9917/10000 (99.17%)

Epoch12 : Loss=0.0038658950943499804  Accuracy=98.10 Batch_id=937: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.46it/s]

Test set: Average loss: 0.0250, Accuracy: 9924/10000 (99.24%)

Epoch13 : Loss=0.01099011767655611  Accuracy=98.22 Batch_id=937: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.40it/s]

Test set: Average loss: 0.0305, Accuracy: 9913/10000 (99.13%)

Epoch14 : Loss=0.04934098199009895  Accuracy=98.22 Batch_id=937: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.50it/s]

Test set: Average loss: 0.0197, Accuracy: 9937/10000 (99.37%)

Epoch15 : Loss=0.005871850997209549  Accuracy=98.41 Batch_id=937: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.44it/s]

Test set: Average loss: 0.0197, Accuracy: 9943/10000 (99.43%)

Epoch16 : Loss=0.2272794544696808  Accuracy=98.45 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.46it/s]

Test set: Average loss: 0.0190, Accuracy: 9944/10000 (99.44%)

Epoch17 : Loss=0.2246362864971161  Accuracy=98.52 Batch_id=937: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:46<00:00, 20.32it/s]

Test set: Average loss: 0.0179, Accuracy: 9951/10000 (99.51%)

Epoch18 : Loss=0.003455648198723793  Accuracy=98.66 Batch_id=937: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.57it/s]

Test set: Average loss: 0.0174, Accuracy: 9944/10000 (99.44%)

Epoch19 : Loss=0.015070061199367046  Accuracy=98.72 Batch_id=937: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:45<00:00, 20.53it/s]

Test set: Average loss: 0.0177, Accuracy: 9948/10000 (99.48%)

Epoch20 : Loss=0.0019444931531324983  Accuracy=98.72 Batch_id=937: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [01:17<00:00, 12.15it/s]

Test set: Average loss: 0.0175, Accuracy: 9951/10000 (99.51%)

=============== Finished group_norm Model ===============
